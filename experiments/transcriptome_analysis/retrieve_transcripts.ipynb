{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee72a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 48 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 16 threads.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pyfaidx import Fasta\n",
    "import os\n",
    "from gtfparse import read_gtf \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a6ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name', 'level', 'tag', 'transcript_id', 'transcript_type', 'transcript_name', 'transcript_support_level', 'havana_transcript', 'exon_number', 'exon_id', 'hgnc_id', 'havana_gene', 'ont', 'protein_id', 'ccdsid', 'artif_dupl']\n"
     ]
    }
   ],
   "source": [
    "cwd = Path(os.getcwd())\n",
    "\n",
    "fa = Fasta( cwd /\n",
    "    (\"transcriptome/gencode.v45.transcripts.fa\"),\n",
    "    key_function=lambda h: h.split(\"|\")[0]\n",
    ")\n",
    "\n",
    "\n",
    "gtf_file = cwd / \"transcriptome/gencode.v45.annotation.gtf\"\n",
    "gtf = read_gtf(gtf_file).to_pandas()\n",
    "\n",
    "tx  = gtf[gtf[\"feature\"] == \"transcript\"][\n",
    "        [\"transcript_id\", \"gene_id\", \"gene_name\",\n",
    "         \"transcript_type\", \"tag\"]]\n",
    "\n",
    "tx[\"sequence\"] = tx[\"transcript_id\"].map(lambda t: str(fa[t]) if t in fa else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b3b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transcripts with non-canonical bases: 2\n"
     ]
    }
   ],
   "source": [
    "tx[\"Non_can_bases\"] = tx[\"sequence\"].apply(\n",
    "    lambda s: sum([1 for c in s if c not in \"ACGT\"]))\n",
    "tx[\"Non_can_bases\"] = tx[\"Non_can_bases\"].apply(lambda x: True if x > 0 else False)\n",
    "\n",
    "print(\"Number of transcripts with non-canonical bases:\",\n",
    "      tx[\"Non_can_bases\"].sum())\n",
    "\n",
    "tx = tx[tx[\"Non_can_bases\"] == False].copy()\n",
    "tx.drop(columns=[\"Non_can_bases\"], inplace=True)\n",
    "tx = tx.reset_index(drop=True)\n",
    "\n",
    "#add 25 P both left and right padding to the sequences\n",
    "tx[\"sequence\"] = tx[\"sequence\"].apply(lambda s: \"P\"*25 + s + \"P\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e99472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tx to file\n",
    "tx_file = cwd / \"transcriptome/gencode_customized.tsv\"\n",
    "tx.to_csv(tx_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51c6dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx[\"tx_idx\"] = np.arange(len(tx), dtype=np.uint32)\n",
    "id2tx = tx[\"transcript_id\"].to_numpy()        # position i → ENST…\n",
    "tx2id = dict(zip(id2tx, np.arange(len(id2tx))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d858d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.full(256, 255, dtype=np.uint8)   # 255 = “invalid”\n",
    "alpha[[ord(x) for x in \"PACGT\"]] = [0,1,2,3,4]\n",
    "\n",
    "def encode(seq: str) -> np.ndarray:\n",
    "    \"\"\"Return a uint8 vector of length len(seq) with values 0–4.\"\"\"\n",
    "    b = np.frombuffer(seq.encode(\"ascii\"), dtype=np.uint8)\n",
    "    return alpha[b]\n",
    "\n",
    "def c_positions(enc_seq: np.ndarray) -> np.ndarray:\n",
    "    # enc_seq == 2 marks a C; skip first/last 25 (they are 'P' anyway)\n",
    "    c_mask = enc_seq == 2\n",
    "    valid = np.flatnonzero(c_mask)\n",
    "    return valid.astype(np.uint32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e69c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_arrs   = []\n",
    "c_pos_arrs = []\n",
    "\n",
    "for _, row in tx.iterrows():\n",
    "    e = encode(row.sequence)\n",
    "    seq_arrs.append(e)\n",
    "    c_pos_arrs.append(c_positions(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef86058",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    cwd / \"transcriptome/tx_data.npz\",\n",
    "    id2tx=id2tx,\n",
    "    seq_arrs=np.array(seq_arrs, dtype=object),\n",
    "    c_pos_arrs=np.array(c_pos_arrs, dtype=object),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
