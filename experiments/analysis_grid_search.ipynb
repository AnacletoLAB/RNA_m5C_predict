{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6002a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_grand_dad = Path(\"./runs\")\n",
    "paths_dad = [x for x in path_grand_dad.iterdir() if x.is_dir()]\n",
    "finished_paths = []\n",
    "mapping_run = {}\n",
    "for path_dad in paths_dad:\n",
    "    if path_dad.stem != \"Transformer\": #here I mistakenly had 2 heads in the transformer\n",
    "        paths_now = [x for x in  [z for z in path_dad.iterdir() if z.is_dir()] if \"averages\" in [y.stem for y in x.iterdir()]]\n",
    "        finished_paths.extend(paths_now)\n",
    "        for path_now in paths_now:\n",
    "            mapping_run[path_now.stem] = path_dad.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84487769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dfs_stds = []\n",
    "dfs_lists = []\n",
    "configurations = {}\n",
    "for path in finished_paths:\n",
    "    with open(path / \"averages.json\", \"r\") as f:\n",
    "        averages = json.load(f)\n",
    "    \n",
    "    df = pd.Series(averages)\n",
    "    dfs.append(df)\n",
    "\n",
    "    with open(path / \"results.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    stds = {k: np.std(v, ddof=1) for k, v in results.items()}\n",
    "    df_std = pd.Series(stds)\n",
    "    dfs_stds.append(df_std)\n",
    "\n",
    "    df_list = pd.Series(results)\n",
    "    dfs_lists.append(df_list)\n",
    "\n",
    "    with open(path / \"config.json\", \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    configurations[path.stem] = config\n",
    "    \n",
    "\n",
    "    \n",
    "df = pd.concat(dfs, axis=1)\n",
    "df.columns = [x.stem for x in finished_paths]\n",
    "df = df.T\n",
    "#map the experiment name to the df\n",
    "df[\"experiment\"] = df.index.map(lambda x: mapping_run[x]) \n",
    "\n",
    "\n",
    "df_std = pd.concat(dfs_stds, axis=1)\n",
    "df_std.columns = [x.stem for x in finished_paths]\n",
    "df_std = df_std.T\n",
    "df_std[\"experiment\"] = df_std.index.map(lambda x: mapping_run[x])\n",
    "\n",
    "df_list = pd.concat(dfs_lists, axis=1)\n",
    "df_list.columns = [x.stem for x in finished_paths]\n",
    "df_list = df_list.T\n",
    "df_list[\"experiment\"] = df_list.index.map(lambda x: mapping_run[x])\n",
    "\n",
    "\n",
    "df.sort_values(by=\"val_auprc_custom\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386d6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_column_names_metrics = {\n",
    "    \"epoch\": \"Number of Epochs\",\n",
    "    \"val_auprc_custom\": \"Weighted AUPRC\",\n",
    "    \"val_auprc\": \"Macro AUPRC\",\n",
    "    \"val_precision\": \"Macro Precision\",\n",
    "    \"val_recall\": \"Macro Recall\",\n",
    "    \"val_f1\": \"Macro F1\",\n",
    "    \"val_auroc\": \"Macro AUROC\",\n",
    "    \"val_accuracy\": \"Accuracy\",\n",
    "    \"val_loss\": \"Validation Loss\",\n",
    "}\n",
    "mapping_column_names_metrics_std = {\n",
    "    \"epoch\": \"Std Number of Epochs\",\n",
    "    \"val_auprc_custom\": \"Std Weighted AUPRC\",\n",
    "    \"val_auprc\": \"Std Macro AUPRC\",\n",
    "    \"val_precision\": \"Std Macro Precision\",\n",
    "    \"val_recall\": \"Std Macro Recall\",\n",
    "    \"val_f1\": \"Std Macro F1\",\n",
    "    \"val_auroc\": \"Std Macro AUROC\",\n",
    "    \"val_accuracy\": \"Std Accuracy\",\n",
    "    \"val_loss\": \"Std Validation Loss\",\n",
    "}\n",
    "mapping_global_search_space_names = {\n",
    "        \"batch_size\": \"Batch Size\",\n",
    "        \"base_seed\": \"Base Seed\",\n",
    "        \"learning_rate\": \"Learning Rate\",\n",
    "        \"weight_decay\": \"Weight Decay\",\n",
    "        \"optimizer\":  \"Optimizer\",\n",
    "        \"scheduler\": \"Scheduler\",\n",
    "        \"criterion\": \"Criterion\",\n",
    "        \"seq_len\": \"Sequence Length\",\n",
    "        \"kmer\": \"K-mer Size\",\n",
    "        \"embed\": \"Embedding Type\",\n",
    "    }\n",
    "\n",
    "mapping_model_search_spaces = {\n",
    "    \"RNN\": {\n",
    "        \"embed_dim\":   \"RNN Embedding Dimension\",\n",
    "        \"hidden_dim\":  \"RNN Hidden Dimension\",\n",
    "        \"num_layers\":   \"RNN Number of Layers\",\n",
    "        \"rnn_type\":     \"RNN Type\",\n",
    "        \"bidirectional\": \"RNN Bidirectional\",\n",
    "        \"dropout\":     \"RNN Dropout Rate\",\n",
    "        \"pooling\":      \"RNN Pooling Type\",\n",
    "    },\n",
    "    \"1DCNN\": {              \n",
    "        \"num_filters\": \"1DCNN Filters\",\n",
    "        \"kernel_sizes\": \"1DCNN Kernels\",\n",
    "        \"pool_sizes\": \"1DCNN Max Pooling\",\n",
    "        \"drop_out_rate\": \"1DCNN Dropout Rate\",\n",
    "    },\n",
    "    \"Transformer\": {\n",
    "        \"embed_dim\": \"Transformer Embedding Dimension\",\n",
    "        \"num_blocks\": \"Transformer Number of Blocks\",\n",
    "        \"num_heads\": \"Transformer Number of Heads\",\n",
    "        \"head_type\":  \"Transformer Pooling Type\",\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57c812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=mapping_column_names_metrics, inplace=True)\n",
    "df.drop(columns=[\"experiment\"], inplace=True)\n",
    "df_std.rename(columns=mapping_column_names_metrics_std, inplace=True)\n",
    "df_std.drop(columns=[\"experiment\"], inplace=True)\n",
    "\n",
    "#merge the two dataframes (the index is the order of df)\n",
    "df_full = pd.concat([df, df_std], axis=1)\n",
    "\n",
    "order = [val for pair in zip(mapping_column_names_metrics.values(),mapping_column_names_metrics_std.values()) for val in pair]\n",
    "df_full = df_full[order]\n",
    "\n",
    "def converge_check(row):\n",
    "    epochs = row[\"epoch\"]\n",
    "    if len([x for x in epochs if x < 140]) < 5:\n",
    "        return \"No\"\n",
    "    return \"Yes\"\n",
    "\n",
    "converge_mapping = df_list.apply(converge_check, axis=1)\n",
    "df_full[\"Converged\"] = converge_mapping\n",
    "df_full[\"Model\"] = df_full.index.map(lambda x: configurations[x][\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca915446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3622659/3402334960.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_full.replace(key, value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "global_params = {k: {mapping_global_search_space_names[key]: value for key, value in v['global_params'].items() \n",
    "                     if mapping_global_search_space_names.get(key) is not None} for k, v in configurations.items()}\n",
    "df_full = df_full.join(pd.DataFrame(global_params).T)\n",
    "\n",
    "scheduler_patience_mapping ={\"RNN\": 4, \"1DCNN\": 6, \"Transformer\": 6}\n",
    "for model, patience in scheduler_patience_mapping.items():\n",
    "    df_full.loc[df_full[\"Model\"] == model, \"Scheduler Patience\"] = patience\n",
    "\n",
    "for model in [\"RNN\", \"Transformer\", \"1DCNN\"]:\n",
    "    configurations_model = {k: v[\"model_params\"] for k, v in configurations.items() if v[\"model\"] == model}\n",
    "    configurations_model ={k: {mapping_model_search_spaces[model][key]: value for key, value in v.items() if \n",
    "                               mapping_model_search_spaces[model].get(key) is not None} for k, v in configurations_model.items()}\n",
    "    configurations_model = pd.DataFrame(configurations_model).T\n",
    "    df_full = df_full.join(configurations_model)\n",
    "    df_full.fillna(\"/\", inplace=True)\n",
    "change_names = {\"avg\": \"Average\", \n",
    "                \"central\": \"Central Vector\",\n",
    "                \"central_attention\": \"Central Weighting\",\n",
    "                \"attention\": \"Weighted\",\n",
    "                \"max\": \"Max\",\n",
    "                \"average_attention\": \"Attention\",\n",
    "                }\n",
    "for key, value in change_names.items():\n",
    "    df_full.replace(key, value, inplace=True)\n",
    "\n",
    "df_full[\"1DCNN Layers\"] = df_full[\"1DCNN Filters\"].apply(lambda x : len(x) if isinstance(x, list) else \"/\")\n",
    "\n",
    "df_full[\"Weight Decay\"] = df_full[\"Weight Decay\"].apply(lambda x: f\"{x:.0e}\" if isinstance(x, float) else x)\n",
    "df_full[\"Learning Rate\"] = df_full[\"Learning Rate\"].apply(lambda x: f\"{x:.0e}\" if isinstance(x, float) else x)\n",
    "df_full[\"Embedding Type\"] = df_full[\"Embedding Type\"].apply(lambda x: \"One-Hot\" if x == \"one_hot\" else x)\n",
    "df_full[\"Criterion\"] = df_full[\"Criterion\"].apply(lambda x: \"Cross Entropy\" if x == \"CrossEntropyLoss\" else x)\n",
    "df_full[\"RNN Bidirectional\"] = df_full[\"RNN Bidirectional\"].apply(lambda x: \"Yes\" if x else \"No\")\n",
    "df_full.to_csv(\"./results/results_grid_search/results_full.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_run_filtered = {k: v for k, v in mapping_run.items() if (v != \"RNN_central_a_little_bigger\") \n",
    "                        and (v != \"RNN_central_weight_decay_check\") and (v != \"Transformer_101\")}\n",
    "\n",
    "mapping_run_filtered_transformer = {k: v for k, v in mapping_run.items() if not v.startswith(\"RNN\") \n",
    "                        and not v.startswith(\"RNN\")}\n",
    "\n",
    "df_fuLl_filtered = df_full.loc[mapping_run_filtered.keys()].copy()\n",
    "df_fuLl_filtered.sort_values(by=\"Weighted AUPRC\", ascending=False, inplace=True)\n",
    "#to excel\n",
    "df_fuLl_filtered.to_excel(\"./results/results_grid_search/results_grid_search.xlsx\", index=True)\n",
    "\n",
    "df_fuLl_filtered_transformer = df_full.loc[mapping_run_filtered_transformer.keys()].copy()\n",
    "df_fuLl_filtered_transformer.sort_values(by=\"Weighted AUPRC\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b47d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns: Scheduler, Scheduler Patience, Base Seed, Criterion\n",
    "df_fuLl_filtered.drop(columns=[\"Scheduler\", \"Scheduler Patience\", \"Base Seed\", \"Criterion\", \"Converged\", \"Validation Loss\"], inplace=True)\n",
    "\n",
    "df_fuLl_filtered_transformer.drop(columns=[\"Scheduler\", \"Scheduler Patience\", \"Base Seed\", \"Criterion\", \"Converged\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deea8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_transformer = df_fuLl_filtered[(df_fuLl_filtered[\"Model\"] == \"Transformer\") & (df_fuLl_filtered[\"Sequence Length\"] == 51)].nlargest(10, \"Weighted AUPRC\").drop(columns=[x for x in df_fuLl_filtered.columns if \"RNN\" in x or \"1DCNN\" in x]).reset_index(drop=True)\n",
    "top_10_1dcnn = df_fuLl_filtered[df_fuLl_filtered[\"Model\"] == \"1DCNN\"].nlargest(10, \"Weighted AUPRC\").drop(columns=[x for x in df_fuLl_filtered.columns if \"RNN\" in x or \"Transformer\" in x]).reset_index(drop=True)\n",
    "top_10_rnn = df_fuLl_filtered[df_fuLl_filtered[\"Model\"] == \"RNN\"].nlargest(10, \"Weighted AUPRC\").drop(columns=[x for x in df_fuLl_filtered.columns if \"1DCNN\" in x or \"Transformer\" in x]).reset_index(drop=True)\n",
    "\n",
    "top_10_difflength_transformer = df_fuLl_filtered_transformer[df_fuLl_filtered_transformer[\"Model\"] == \"Transformer\"].nlargest(10, \"Weighted AUPRC\").drop(columns=[x for x in df_fuLl_filtered_transformer.columns if \"RNN\" in x or \"1DCNN\" in x]).reset_index(drop=True)\n",
    "\n",
    "top_10_transformer.index = top_10_transformer.index + 1\n",
    "top_10_1dcnn.index = top_10_1dcnn.index + 1\n",
    "top_10_rnn.index = top_10_rnn.index + 1\n",
    "top_10_difflength_transformer.index = top_10_difflength_transformer.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ea777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_and_std(dataframe):\n",
    "    metrics = list(mapping_column_names_metrics.values())\n",
    "    for m in metrics:\n",
    "        std_col = f\"Std {m}\"\n",
    "        if m in dataframe.columns and std_col in dataframe.columns:\n",
    "            if \"Epochs\" in m:\n",
    "                dataframe[m] = dataframe.apply(\n",
    "                    lambda row: f\"$ {row[m]:.1f}{{\\\\scriptstyle \\\\pm{row[std_col]:.1f}}}$\",\n",
    "                    axis=1\n",
    "                )\n",
    "            else:\n",
    "                dataframe[m] = dataframe.apply(\n",
    "                    lambda row: f\"$ {row[m]:.3f}{{\\\\scriptstyle \\\\pm{row[std_col]:.3f}}}$\",\n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "    std_cols = [f\"Std {m}\" for m in metrics if f\"Std {m}\" in dataframe.columns]\n",
    "    dataframe.drop(columns=std_cols, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "top_10_transformer = truncate_and_std(top_10_transformer)\n",
    "top_10_1dcnn = truncate_and_std(top_10_1dcnn)\n",
    "top_10_rnn = truncate_and_std(top_10_rnn)\n",
    "top_10_difflength_transformer = truncate_and_std(top_10_difflength_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbe629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only the first 10 columns of each (split in two)\n",
    "top_10_transformer_metrics = top_10_transformer.iloc[:, :8]\n",
    "top_10_difflength_transformer_metrics = top_10_difflength_transformer.iloc[:, :8]\n",
    "top_10_1dcnn_metrics = top_10_1dcnn.iloc[:, :8]\n",
    "top_10_rnn_metrics = top_10_rnn.iloc[:, :8]\n",
    "top_10_transformer_params = top_10_transformer.iloc[:, 8:]\n",
    "top_10_transformer_params.columns = [col.replace(\"Transformer \", \"\") for col in top_10_transformer_params.columns]\n",
    "top_10_difflength_transformer_params = top_10_difflength_transformer.iloc[:, 8:]\n",
    "top_10_difflength_transformer_params.columns = [col.replace(\"Transformer \", \"\") for col in top_10_difflength_transformer_params.columns]\n",
    "top_10_1dcnn_params = top_10_1dcnn.iloc[:, 8:]\n",
    "top_10_1dcnn_params.columns = [col.replace(\"1DCNN \", \"\") for col in top_10_1dcnn_params.columns]\n",
    "top_10_rnn_params = top_10_rnn.iloc[:, 8:]\n",
    "top_10_rnn_params.columns = [col.replace(\"RNN \", \"\") for col in top_10_rnn_params.columns]\n",
    "top_10_rnn_params.drop(columns=[\"Type\", \"Bidirectional\"], inplace=True)  # RNN Number of Layers is not a parameter in the grid search\n",
    "\n",
    "top_3_overall_metrics = pd.concat([pd.DataFrame(top_10_rnn_metrics.iloc[0]).T, \n",
    "           pd.DataFrame(top_10_transformer_metrics.iloc[0]).T, \n",
    "           pd.DataFrame(top_10_1dcnn_metrics.iloc[0]).T], \n",
    "          axis=0).drop(columns=(\"Number of Epochs\"))\n",
    "top_3_overall_metrics.index = [\"RNN\", \"Transformer\", \"1DCNN\"]\n",
    "\n",
    "\n",
    "top_10_difflength_transformer_metrics[\"Sequence Length\"] = top_10_difflength_transformer_params[\"Sequence Length\"]\n",
    "#set first column to sequence length\n",
    "top_10_difflength_transformer_metrics = top_10_difflength_transformer_metrics[[\"Sequence Length\"] + [col for col in top_10_difflength_transformer_metrics.columns if col != \"Sequence Length\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a378fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_transformer_metrics = top_10_transformer_metrics.to_latex(escape=False)\n",
    "latex_1dcnn_metrics = top_10_1dcnn_metrics.to_latex(escape=False)\n",
    "latex_rnn_metrics = top_10_rnn_metrics.to_latex(escape=False)\n",
    "latex_transformer_params = top_10_transformer_params.to_latex(escape=False)\n",
    "latex_1dcnn_params = top_10_1dcnn_params.to_latex(escape=False)\n",
    "latex_rnn_params = top_10_rnn_params.to_latex(escape=False)\n",
    "\n",
    "latex_top3_overall_metrics = top_3_overall_metrics.to_latex(escape=False)\n",
    "\n",
    "latex_difflength_transformer_metrics = top_10_difflength_transformer_metrics.to_latex(escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa560d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      " & Number of Epochs & Weighted AUPRC & Macro AUPRC & Macro Precision & Macro Recall & Macro F1 & Macro AUROC & Accuracy \\\\\n",
      "\\midrule\n",
      "1 & $ 22.6{\\scriptstyle \\pm11.1}$ & $ 0.973{\\scriptstyle \\pm0.002}$ & $ 0.968{\\scriptstyle \\pm0.002}$ & $ 0.889{\\scriptstyle \\pm0.022}$ & $ 0.951{\\scriptstyle \\pm0.004}$ & $ 0.917{\\scriptstyle \\pm0.012}$ & $ 0.991{\\scriptstyle \\pm0.001}$ & $ 0.936{\\scriptstyle \\pm0.003}$ \\\\\n",
      "2 & $ 26.2{\\scriptstyle \\pm10.5}$ & $ 0.973{\\scriptstyle \\pm0.002}$ & $ 0.967{\\scriptstyle \\pm0.003}$ & $ 0.899{\\scriptstyle \\pm0.010}$ & $ 0.948{\\scriptstyle \\pm0.008}$ & $ 0.922{\\scriptstyle \\pm0.006}$ & $ 0.992{\\scriptstyle \\pm0.001}$ & $ 0.936{\\scriptstyle \\pm0.005}$ \\\\\n",
      "3 & $ 23.6{\\scriptstyle \\pm5.9}$ & $ 0.973{\\scriptstyle \\pm0.001}$ & $ 0.967{\\scriptstyle \\pm0.001}$ & $ 0.878{\\scriptstyle \\pm0.010}$ & $ 0.954{\\scriptstyle \\pm0.003}$ & $ 0.912{\\scriptstyle \\pm0.007}$ & $ 0.992{\\scriptstyle \\pm0.001}$ & $ 0.936{\\scriptstyle \\pm0.004}$ \\\\\n",
      "4 & $ 16.6{\\scriptstyle \\pm4.3}$ & $ 0.972{\\scriptstyle \\pm0.001}$ & $ 0.966{\\scriptstyle \\pm0.002}$ & $ 0.892{\\scriptstyle \\pm0.016}$ & $ 0.951{\\scriptstyle \\pm0.009}$ & $ 0.918{\\scriptstyle \\pm0.007}$ & $ 0.992{\\scriptstyle \\pm0.001}$ & $ 0.939{\\scriptstyle \\pm0.004}$ \\\\\n",
      "5 & $ 23.8{\\scriptstyle \\pm6.5}$ & $ 0.972{\\scriptstyle \\pm0.002}$ & $ 0.966{\\scriptstyle \\pm0.003}$ & $ 0.892{\\scriptstyle \\pm0.010}$ & $ 0.954{\\scriptstyle \\pm0.004}$ & $ 0.920{\\scriptstyle \\pm0.007}$ & $ 0.991{\\scriptstyle \\pm0.001}$ & $ 0.937{\\scriptstyle \\pm0.003}$ \\\\\n",
      "6 & $ 25.0{\\scriptstyle \\pm9.3}$ & $ 0.972{\\scriptstyle \\pm0.002}$ & $ 0.966{\\scriptstyle \\pm0.003}$ & $ 0.889{\\scriptstyle \\pm0.012}$ & $ 0.952{\\scriptstyle \\pm0.006}$ & $ 0.918{\\scriptstyle \\pm0.005}$ & $ 0.991{\\scriptstyle \\pm0.001}$ & $ 0.937{\\scriptstyle \\pm0.004}$ \\\\\n",
      "7 & $ 16.6{\\scriptstyle \\pm7.9}$ & $ 0.972{\\scriptstyle \\pm0.003}$ & $ 0.966{\\scriptstyle \\pm0.004}$ & $ 0.880{\\scriptstyle \\pm0.012}$ & $ 0.953{\\scriptstyle \\pm0.003}$ & $ 0.912{\\scriptstyle \\pm0.008}$ & $ 0.991{\\scriptstyle \\pm0.001}$ & $ 0.936{\\scriptstyle \\pm0.005}$ \\\\\n",
      "8 & $ 14.2{\\scriptstyle \\pm2.9}$ & $ 0.972{\\scriptstyle \\pm0.003}$ & $ 0.965{\\scriptstyle \\pm0.005}$ & $ 0.890{\\scriptstyle \\pm0.002}$ & $ 0.952{\\scriptstyle \\pm0.010}$ & $ 0.918{\\scriptstyle \\pm0.004}$ & $ 0.992{\\scriptstyle \\pm0.001}$ & $ 0.936{\\scriptstyle \\pm0.005}$ \\\\\n",
      "9 & $ 16.8{\\scriptstyle \\pm1.9}$ & $ 0.972{\\scriptstyle \\pm0.001}$ & $ 0.965{\\scriptstyle \\pm0.002}$ & $ 0.882{\\scriptstyle \\pm0.006}$ & $ 0.955{\\scriptstyle \\pm0.003}$ & $ 0.914{\\scriptstyle \\pm0.004}$ & $ 0.992{\\scriptstyle \\pm0.001}$ & $ 0.937{\\scriptstyle \\pm0.005}$ \\\\\n",
      "10 & $ 15.0{\\scriptstyle \\pm6.2}$ & $ 0.972{\\scriptstyle \\pm0.002}$ & $ 0.965{\\scriptstyle \\pm0.002}$ & $ 0.897{\\scriptstyle \\pm0.014}$ & $ 0.947{\\scriptstyle \\pm0.012}$ & $ 0.920{\\scriptstyle \\pm0.007}$ & $ 0.991{\\scriptstyle \\pm0.001}$ & $ 0.939{\\scriptstyle \\pm0.004}$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_transformer_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a168cc",
   "metadata": {},
   "source": [
    "### After training the best models on grid search, we record their performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6572056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import pickle, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.training_metrics import test_metrics\n",
    "\n",
    "from utils.search_space import model_mapping\n",
    "from utils.seed         import set_global_seed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1334e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Transformer:\n",
      "{'test_f1': 0.9259086140908594, 'test_precision': 0.9003846107643996, 'test_recall': 0.9561733158367897, 'test_auprc': 0.9703996367809304, 'test_auprc_custom': 0.9756161668517117, 'test_auroc': 0.9921033629406454, 'test_accuracy': 0.9405727318803851}\n",
      "Confusion Matrix:\n",
      "      0     1     2   3    4\n",
      "0  3623   243    37  13   30\n",
      "1   113  2145     0   2   16\n",
      "2     5     0  1376   0    0\n",
      "3     5     0     0  96    0\n",
      "4     5     0     0   0  183\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for RNN:\n",
      "{'test_f1': 0.9300741894820372, 'test_precision': 0.9081558255056714, 'test_recall': 0.9550264828327129, 'test_auprc': 0.9725591033555581, 'test_auprc_custom': 0.9774630426017565, 'test_auroc': 0.993070435558213, 'test_accuracy': 0.9433603649265079}\n",
      "Confusion Matrix:\n",
      "      0     1     2   3    4\n",
      "0  3658   213    35  13   27\n",
      "1   134  2131     0   3    8\n",
      "2     3     0  1378   0    0\n",
      "3     6     0     0  95    0\n",
      "4     5     0     0   0  183\n",
      "\n",
      "==================================================\n",
      "\n",
      "Results for 1DCNN:\n",
      "{'test_f1': 0.9147777900273761, 'test_precision': 0.8788531970866835, 'test_recall': 0.960662299655439, 'test_auprc': 0.9679046884703354, 'test_auprc_custom': 0.9738414723314048, 'test_auroc': 0.9919307265695181, 'test_accuracy': 0.940319310694374}\n",
      "Confusion Matrix:\n",
      "      0     1     2   3    4\n",
      "0  3604   249    37  20   36\n",
      "1    89  2157     0   4   26\n",
      "2     3     0  1378   0    0\n",
      "3     4     0     0  97    0\n",
      "4     3     0     0   0  185\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping_models = {\n",
    "    \"Transformer\": {\"path_conf\":Path(\"./runs/Transformer_average_attention/run_11_30_05_2025_15_41_04/config.json\"),\n",
    "                    \"path_weights\": Path(\"./logs/Transformer/Transformer_epoch_23.pt\")},\n",
    "    \"RNN\": {\"path_conf\":Path(\"./runs/RNN_central_attention/run_32_19_05_2025_23_41_30/config.json\"),\n",
    "            \"path_weights\": Path(\"./logs/RNN/RNN_epoch_43.pt\")},\n",
    "    \"1DCNN\": {\"path_conf\":Path(\"./runs/1DCNN/run_11_24_05_2025_16_51_52/config.json\"),\n",
    "                    \"path_weights\": Path(\"./logs/1DCNN/1DCNN_epoch_50.pt\")},\n",
    "}\n",
    "\n",
    "def test_res(path_config, path_weights):\n",
    "    with open(path_config, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    model_name = config[\"model\"]\n",
    "    model_params = config[\"model_params\"]\n",
    "\n",
    "    seq_len = model_params[\"seq_len\"]\n",
    "    embed = model_params[\"embed\"]\n",
    "    kmer = model_params[\"kmer\"]\n",
    "\n",
    "    batch_size = 256\n",
    "    seed = 42\n",
    "    set_global_seed(seed)\n",
    "\n",
    "    dataset_path = Path(os.getcwd()).parent / \"dataset/test_set.pickle\"\n",
    "    with open(dataset_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "\n",
    "    from dataset_generation.val_dataset import Datasetval as Dataset_\n",
    "\n",
    "    dataset_ = Dataset_(\n",
    "        data_dict=data,\n",
    "        base_seed=seed,\n",
    "        embed=embed,\n",
    "        kmer=kmer,\n",
    "        seq_len=seq_len,\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(dataset_, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "    model = model_mapping(model_name)(**model_params)\n",
    "    model.load_state_dict(torch.load(path_weights, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    results, cmx = test_metrics(model, dataloader)\n",
    "    return results, cmx\n",
    "\n",
    "results_all = {}\n",
    "cmx_all = {}\n",
    "for model, paths in mapping_models.items():\n",
    "    path_config = paths[\"path_conf\"]\n",
    "    path_weights = paths[\"path_weights\"]\n",
    "\n",
    "    results, cmx = test_res(path_config, path_weights)\n",
    "\n",
    "    print(f\"Results for {model}:\")\n",
    "    print(results)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cmx)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    results_all[model] = results\n",
    "    cmx_all[model] = cmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db43734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      " & Weighted AUPRC & Macro AUPRC & Macro Precision & Macro Recall & Macro F1 & Macro AUROC & Accuracy \\\\\n",
      "\\midrule\n",
      "RNN & $0.977$ & $0.973$ & $0.908$ & $0.955$ & $0.930$ & $0.993$ & $0.943$ \\\\\n",
      "Transformer & $0.976$ & $0.970$ & $0.900$ & $0.956$ & $0.926$ & $0.992$ & $0.941$ \\\\\n",
      "1DCNN & $0.974$ & $0.968$ & $0.879$ & $0.961$ & $0.915$ & $0.992$ & $0.940$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping_column_names_metrics = {\n",
    "    \"test_auprc_custom\": \"Weighted AUPRC\",\n",
    "    \"test_auprc\": \"Macro AUPRC\",\n",
    "    \"test_precision\": \"Macro Precision\",\n",
    "    \"test_recall\": \"Macro Recall\",\n",
    "    \"test_f1\": \"Macro F1\",\n",
    "    \"test_auroc\": \"Macro AUROC\",\n",
    "    \"test_accuracy\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "\n",
    "res_test = pd.DataFrame(results_all).T\n",
    "res_test.rename(columns=mapping_column_names_metrics, inplace=True)\n",
    "#reorder the columns\n",
    "res_test = res_test[list(mapping_column_names_metrics.values())]\n",
    "res_test.sort_values(by=\"Weighted AUPRC\", ascending=False, inplace=True)\n",
    "res_test = res_test.map(lambda x: f\"${x:.3f}$\")\n",
    "print(res_test.to_latex(escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rinalmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
